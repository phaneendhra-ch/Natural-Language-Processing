{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d53142",
   "metadata": {},
   "source": [
    "# Introduction to Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5939b11",
   "metadata": {},
   "source": [
    "### Lemmatization looks at surrounding text to determine a given wordâ€™s part of speech, it does not categorize phrases.\n",
    "\n",
    "### Main Intuition :\n",
    "**Stemming** just removes or stems the last few characters of a word, often leading to incorrect meanings and spelling. **Lemmatization** considers the context and converts the word to its meaningful base form, which is called **Lemma**\n",
    "\n",
    "### Source : https://towardsdatascience.com/stemming-vs-lemmatization-2daddabcb221#:~:text=Stemming%20and%20Lemmatization%20both%20generate,words%20which%20makes%20it%20faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14beebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy will only implement Lemmatization but not Stemming\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88bb41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afd6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Automobile Industry is growing rapidly and the era has just began\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b50705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text           Lemma          Token Lemma\n",
      "\n",
      "Automobile     automobile     7211811266693931283\n",
      "Industry       industry       16409696763006672153\n",
      "is             be             10382539506755952630\n",
      "growing        grow           17623831665190758874\n",
      "rapidly        rapidly        3089136833334612597\n",
      "and            and            2283656566040971221\n",
      "the            the            7425985699627899538\n",
      "era            era            7478797442728669872\n",
      "has            have           14692702688101715474\n",
      "just           just           7148522813498185515\n",
      "began          begin          11234294172215200015\n"
     ]
    }
   ],
   "source": [
    "text = \"Text\"\n",
    "lemma = \"Lemma\"\n",
    "tk_ = \"Token Lemma\"\n",
    "print(f\"{text:{15}}{lemma:{15}}{tk_}\",end=\"\\n\\n\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{15}}{token.lemma_:{15}}{token.lemma}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
